# LVI-SAM æ ¡å›­åœºæ™¯SLAMä¼˜åŒ–é¡¹ç›® - å®Œæ•´æŒ‡å—

## ğŸ“‹ é¡¹ç›®æ¦‚è§ˆ

è¿™æ˜¯ä¸€ä¸ªåŸºäºLVI-SAMæ¡†æ¶ï¼Œé’ˆå¯¹æ ¡å›­åœºæ™¯çš„SLAMç³»ç»Ÿä¼˜åŒ–ç ”ç©¶é¡¹ç›®ã€‚é¡¹ç›®åŒ…å«å®Œæ•´çš„å®ç°æ–¹æ¡ˆã€æ€§èƒ½è¯„ä¼°æ¡†æ¶å’Œå®éªŒæŒ‡å¯¼ã€‚

### é¡¹ç›®è¦ç‚¹

| é¡¹ç›® | è¯¦æƒ… |
|------|------|
| **åŸºç¡€æ¡†æ¶** | LVI-SAM (ç´§è€¦åˆLiDAR-è§†è§‰-æƒ¯æ€§SLAM) |
| **ä¼ æ„Ÿå™¨é…ç½®** | RealSense D435i RGB-D + Velodyne VLP-16 + MTi-680G IMU |
| **æ•°æ®é›†** | æ ¡å›­åœºæ™¯ï¼ŒåŒ…å«åœ°é¢çœŸå€¼(RTK) |
| **ä¼˜åŒ–æ–¹å‘** | è§†è§‰é‡Œç¨‹è®¡ã€æ¿€å…‰é‡Œç¨‹è®¡ã€å›ç¯æ£€æµ‹ã€å› å­å›¾ä¼˜åŒ– |
| **è¯„ä¼°æŒ‡æ ‡** | APE, ATE, ARE (é€šè¿‡EVOå·¥å…·) |
| **é¢„æœŸæ”¶ç›Š** | å®šä½ç²¾åº¦æå‡ 10-30%, ç³»ç»Ÿé²æ£’æ€§å¢å¼º |

---

## ğŸ¯ æ ¸å¿ƒæ”¹è¿›æ–¹æ¡ˆé€Ÿè§ˆ

### 1ï¸âƒ£ è§†è§‰é‡Œç¨‹è®¡æ”¹è¿›

```python
# ç›®æ ‡: æå‡ç‰¹å¾ç‚¹è´¨é‡å’Œæ·±åº¦ä¼°è®¡ç²¾åº¦

æ”¹è¿›å†…å®¹:
â”œâ”€â”€ ç‰¹å¾æå–ç®—æ³• (ORB â†’ SuperPoint)
â”œâ”€â”€ ç‰¹å¾ç‚¹å‡åŒ€åˆ†å¸ƒ (æ”¹è¿›åˆ†å¸ƒç­–ç•¥)
â”œâ”€â”€ æ·±åº¦ä¼°è®¡èåˆ (LiDAR + å•ç›®CNN)
â””â”€â”€ è‡ªé€‚åº”è·Ÿè¸ª (åŠ¨æ€è°ƒæ•´å‚æ•°)

æ€§èƒ½æŒ‡æ ‡:
â”œâ”€â”€ ç‰¹å¾ç‚¹è¿½è¸ªç‡: åŸ95% â†’ ç›®æ ‡98%
â”œâ”€â”€ æ·±åº¦ä¼°è®¡ç²¾åº¦: åŸÂ±15cm â†’ ç›®æ ‡Â±10cm
â””â”€â”€ è®¡ç®—æ•ˆç‡: ä¿æŒå®æ—¶(<30ms/frame)
```

### 2ï¸âƒ£ æ¿€å…‰é‡Œç¨‹è®¡æ”¹è¿›

```python
# ç›®æ ‡: å¤„ç†åŠ¨æ€ç‰©ä½“ï¼Œæ”¹è¿›ç‚¹äº‘é…å‡†

æ”¹è¿›å†…å®¹:
â”œâ”€â”€ åŠ¨æ€ç‰©ä½“æ£€æµ‹ (è¿åŠ¨ä¸€è‡´æ€§åˆ†æ)
â”œâ”€â”€ ç‚¹äº‘å»å™ª (èšç±»+æ®‹å·®åˆ†æ)
â”œâ”€â”€ é…å‡†ç®—æ³•å‡çº§ (ICP â†’ NDT/Generalized-ICP)
â””â”€â”€ å¤šå±‚çº§é…å‡† (ç²—åˆ°ç»†ç­–ç•¥)

æ€§èƒ½æŒ‡æ ‡:
â”œâ”€â”€ åŠ¨æ€ç‚¹å»é™¤ç‡: ç›®æ ‡>90%
â”œâ”€â”€ é…å‡†æ”¶æ•›é€Ÿåº¦: åŸ30ms â†’ ç›®æ ‡20ms
â””â”€â”€ é…å‡†ç²¾åº¦æå‡: Â±2cm
```

### 3ï¸âƒ£ å›ç¯æ£€æµ‹æ”¹è¿›

```python
# ç›®æ ‡: ä½¿ç”¨æ·±åº¦å­¦ä¹ æå‡å›ç¯æ£€æµ‹å‡†ç¡®ç‡

æ”¹è¿›å†…å®¹:
â”œâ”€â”€ CNNç‰¹å¾æå– (ResNet-18ç¼–ç å™¨)
â”œâ”€â”€ Siameseç½‘ç»œ (ç›¸ä¼¼åº¦è®¡ç®—)
â”œâ”€â”€ 3Dä¿¡æ¯èåˆ (RGB-Dæ·±åº¦)
â””â”€â”€ ç½®ä¿¡åº¦è¯„åˆ† (é™ä½è¯¯æ£€ç‡)

æ€§èƒ½æŒ‡æ ‡:
â”œâ”€â”€ å›ç¯æ­£ç¡®ç‡: åŸ70% â†’ ç›®æ ‡>95%
â”œâ”€â”€ è¯¯æ£€ç‡: åŸ<5% â†’ ç›®æ ‡<2%
â””â”€â”€ æ£€æµ‹é€Ÿåº¦: <100ms/frame
```

### 4ï¸âƒ£ å› å­å›¾ä¼˜åŒ–æ”¹è¿›

```python
# ç›®æ ‡: å¢åŠ çº¦æŸã€æ”¹è¿›ä¼˜åŒ–ç­–ç•¥

æ”¹è¿›å†…å®¹:
â”œâ”€â”€ æ·±åº¦å­¦ä¹ å›ç¯å› å­ (ç½®ä¿¡åº¦åŠ æƒ)
â”œâ”€â”€ æ”¹è¿›çš„LiDARå› å­ (ç‚¹é¢è·ç¦»)
â”œâ”€â”€ å…‰åº¦åº¦é‡å› å­ (ç›´æ¥æ³•ä¼˜åŒ–)
â””â”€â”€ åŠ¨æ€å™ªå£°æ¨¡å‹ (è‡ªé€‚åº”åæ–¹å·®)

æ€§èƒ½æŒ‡æ ‡:
â”œâ”€â”€ å…¨å±€ä¸€è‡´æ€§: æå‡æ˜¾è‘—
â”œâ”€â”€ è½¨è¿¹å¹³æ»‘åº¦: æ”¹å–„
â””â”€â”€ é—­åˆè¯¯å·®: å‡å°50%
```

---

## ğŸ“¦ å®Œæ•´æ–‡ä»¶ç»“æ„

```
/home/cx/lvi-sam/
â”‚
â”œâ”€â”€ ğŸ“„ PROJECT_PLAN.md                    # é¡¹ç›®æ€»ä½“è§„åˆ’
â”œâ”€â”€ ğŸ“„ IMPLEMENTATION_GUIDE.md             # è¯¦ç»†å®ç°æŒ‡å—
â”œâ”€â”€ ğŸ“„ CODE_ANALYSIS.md                   # åŸå§‹ä»£ç åˆ†æ
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ LVI-SAM-Easyused/                 # åŸå§‹LVI-SAMä»£ç 
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ lidar_odometry/
â”‚       â”‚   â””â”€â”€ visual_odometry/
â”‚       â”œâ”€â”€ config/                       # ä¼ æ„Ÿå™¨é…ç½®
â”‚       â”œâ”€â”€ launch/                       # ROSå¯åŠ¨æ–‡ä»¶
â”‚       â””â”€â”€ CMakeLists.txt
â”‚
â”œâ”€â”€ improvements/                         # ğŸ†• æ”¹è¿›æ¨¡å—ç›®å½•
â”‚   â”œâ”€â”€ visual_feature_enhanced/
â”‚   â”‚   â”œâ”€â”€ enhanced_tracker.h
â”‚   â”‚   â”œâ”€â”€ enhanced_tracker.cpp
â”‚   â”‚   â””â”€â”€ CMakeLists.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ depth_estimation/
â”‚   â”‚   â”œâ”€â”€ depth_predictor.h
â”‚   â”‚   â”œâ”€â”€ depth_predictor.cpp
â”‚   â”‚   â””â”€â”€ monocular_depth.py
â”‚   â”‚
â”‚   â”œâ”€â”€ dynamic_removal/
â”‚   â”‚   â”œâ”€â”€ dynamic_filter.h
â”‚   â”‚   â”œâ”€â”€ dynamic_filter.cpp
â”‚   â”‚   â””â”€â”€ motion_consistency.h
â”‚   â”‚
â”‚   â”œâ”€â”€ point_cloud_matching/
â”‚   â”‚   â”œâ”€â”€ advanced_matcher.h
â”‚   â”‚   â”œâ”€â”€ advanced_matcher.cpp
â”‚   â”‚   â”œâ”€â”€ ndt_matcher.h
â”‚   â”‚   â””â”€â”€ p2l_icp.h
â”‚   â”‚
â”‚   â”œâ”€â”€ loop_closure_dl/
â”‚   â”‚   â”œâ”€â”€ deep_loop_detector.py         # âœ… å·²å®ç°
â”‚   â”‚   â”œâ”€â”€ siamese_network.py
â”‚   â”‚   â”œâ”€â”€ feature_extractor.py
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â””â”€â”€ siamese_trained.pth       # è®­ç»ƒçš„æ¨¡å‹æƒé‡
â”‚   â”‚
â”‚   â””â”€â”€ factor_graph_opt/
â”‚       â”œâ”€â”€ custom_factors.h
â”‚       â”œâ”€â”€ deep_loop_factor.h
â”‚       â”œâ”€â”€ improved_lidar_factor.h
â”‚       â””â”€â”€ photometric_factor.h
â”‚
â”œâ”€â”€ scripts/                              # ğŸ†• å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ evaluate_trajectory.py             # âœ… å·²å®ç° - EVOè¯„ä¼°
â”‚   â”œâ”€â”€ benchmark_suite.py                 # âœ… å·²å®ç° - åŸºå‡†æµ‹è¯•
â”‚   â”œâ”€â”€ train_loop_detector.py
â”‚   â”œâ”€â”€ hyperparameter_tuning.py
â”‚   â””â”€â”€ generate_report.py
â”‚
â”œâ”€â”€ experiments/                          # ğŸ†• å®éªŒç®¡ç†ç›®å½•
â”‚   â”œâ”€â”€ baseline/
â”‚   â”‚   â”œâ”€â”€ trajectory.txt
â”‚   â”‚   â”œâ”€â”€ metrics.json
â”‚   â”‚   â””â”€â”€ README.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ improved_v1/
â”‚   â”œâ”€â”€ improved_v2/
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ trajectories/
â”‚       â”œâ”€â”€ metrics/
â”‚       â”œâ”€â”€ plots/
â”‚       â”œâ”€â”€ comparison_results.csv
â”‚       â”œâ”€â”€ method_comparison.png
â”‚       â””â”€â”€ benchmark_report.json
â”‚
â”œâ”€â”€ home_data/                            # æ•°æ®é›†
â”‚   â”œâ”€â”€ husky.bag (22GB)
â”‚   â””â”€â”€ gt.txt (71MB, åœ°é¢çœŸå€¼)
â”‚
â””â”€â”€ reports/                              # ğŸ†• æŠ¥å‘Šç›®å½•
    â”œâ”€â”€ final_report.md
    â”œâ”€â”€ figures/
    â””â”€â”€ tables/
```

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### ç¬¬ä¸€æ¬¡è¿è¡Œ

```bash
# 1. è®¾ç½®ç¯å¢ƒ
cd /home/cx/lvi-sam
source devel/setup.bash

# 2. ä¸‰ä¸ªç‹¬ç«‹ç»ˆç«¯å¯åŠ¨ROSç³»ç»Ÿ
# ç»ˆç«¯A: ROSæ ¸å¿ƒ
roscore

# ç»ˆç«¯B: LVI-SAMç³»ç»Ÿ
roslaunch lvi_sam Husky.launch

# ç»ˆç«¯C: æ’­æ”¾æ•°æ®é›†
rosbag play home_data/husky.bag

# 3. ç­‰å¾…å¤„ç†å®Œæˆï¼ˆ10-20åˆ†é’Ÿï¼‰
# ç»“æœä¿å­˜åœ¨ ~/lvi-sam/results/
```

### æ€§èƒ½è¯„ä¼°

```bash
# åŸºçº¿è¯„ä¼°
python scripts/evaluate_trajectory.py \
    --estimated results/trajectory.txt \
    --reference home_data/gt.txt \
    --method "baseline_lvi_sam" \
    --output experiments/baseline

# æŸ¥çœ‹ç»“æœ
cat experiments/baseline/baseline_lvi_sam_metrics.json
```

### å¯¹æ¯”å¤šç‰ˆæœ¬

```bash
# è¿è¡Œç»¼åˆåŸºå‡†æµ‹è¯•
python scripts/benchmark_suite.py --all \
    --output experiments/final_evaluation

# æŸ¥çœ‹å¯¹æ¯”ç»“æœ
cat experiments/final_evaluation/comparison_results.csv
# æŸ¥çœ‹å¯è§†åŒ–å¯¹æ¯”
open experiments/final_evaluation/method_comparison.png
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡è¯´æ˜

### APE (Absolute Pose Error) - ç»å¯¹ä½å§¿è¯¯å·®
```
è¡¡é‡ä¼°è®¡è½¨è¿¹ä¸çœŸå€¼è½¨è¿¹çš„ç»å¯¹å·®å¼‚
APE = ||p_ref(t) - p_est(t)||
å•ä½: ç±³ (m)
æ›´å°æ›´å¥½

å…¸å‹å€¼: 0.05-0.20 m
```

### ATE (Absolute Trajectory Error) - ç»å¯¹è½¨è¿¹è¯¯å·®
```
è¡¡é‡æ•´ä½“è½¨è¿¹çš„ç´¯ç§¯è¯¯å·®
ATE = RMSE of {||p_ref(t) - p_est(t)||}_t
å•ä½: ç±³ (m)
æ›´å°æ›´å¥½

å…¸å‹å€¼: 0.05-0.25 m
```

### ARE (Absolute Rotation Error) - ç»å¯¹æ—‹è½¬è¯¯å·®
```
è¡¡é‡å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§
ARE = arccos(trace(R_rel) - 1) / 2
å•ä½: åº¦æ•° (deg)
æ›´å°æ›´å¥½

å…¸å‹å€¼: 0.5-5.0 deg
```

---

## ğŸ’» å…³é”®å®ç°æ–‡ä»¶

### âœ… å·²å®Œæˆçš„å®ç°

#### 1. æ·±åº¦å­¦ä¹ å›ç¯æ£€æµ‹ 
**æ–‡ä»¶**: `improvements/loop_closure_dl/deep_loop_detector.py`

```python
# æ ¸å¿ƒç‰¹æ€§:
- å­ªç”Ÿç½‘ç»œæ¶æ„ (Siamese Network)
- å®æ—¶ç‰¹å¾æå–å’Œç›¸ä¼¼åº¦è®¡ç®—
- ç‰¹å¾æ•°æ®åº“ç®¡ç†
- çµæ´»çš„æŸ¥è¯¢æ¥å£

# ä½¿ç”¨ç¤ºä¾‹:
detector = DeepLoopDetector(model_path="model.pth")
detector.add_frame(image, frame_id=0)
candidates = detector.detect_loop_closure(query_image, query_id=100)
for cand in candidates:
    print(f"Frame {cand['query_id']} -> {cand['reference_id']}: {cand['similarity']:.4f}")
```

#### 2. è½¨è¿¹è¯„ä¼°å·¥å…·
**æ–‡ä»¶**: `scripts/evaluate_trajectory.py`

```python
# æ ¸å¿ƒåŠŸèƒ½:
- åŠ è½½TUMæ ¼å¼è½¨è¿¹
- è®¡ç®—APE, ATE, AREç­‰æŒ‡æ ‡
- ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
- RMSEç»Ÿè®¡åˆ†æ

# ä½¿ç”¨ç¤ºä¾‹:
evaluator = TrajectoryEvaluator(output_dir="results")
metrics = evaluator.evaluate(
    estimated_traj="traj_est.txt",
    reference_traj="gt.txt",
    method_name="my_method"
)
print(f"APE RMSE: {metrics['APE_RMSE']:.6f} m")
```

#### 3. åŸºå‡†æµ‹è¯•å¥—ä»¶
**æ–‡ä»¶**: `scripts/benchmark_suite.py`

```python
# æ ¸å¿ƒåŠŸèƒ½:
- è‡ªåŠ¨è¿è¡Œå¤šä¸ªSLAMé…ç½®
- æ”¶é›†å’Œæ¯”è¾ƒæ€§èƒ½æŒ‡æ ‡
- ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šå’Œå›¾è¡¨
- å®éªŒè¿½è¸ªå’Œæ—¥å¿—è®°å½•

# ä½¿ç”¨ç¤ºä¾‹:
suite = BenchmarkSuite()
suite.run_all_benchmarks([
    {'name': 'baseline', 'launch': 'file.launch', ...},
    {'name': 'improved_v1', 'launch': 'file_v1.launch', ...}
])
suite.generate_report()
```

### ğŸ“ éœ€è¦å®Œæˆçš„å®ç°

| æ–‡ä»¶ | çŠ¶æ€ | ä¼˜å…ˆçº§ |
|------|------|--------|
| visual_feature_enhanced/enhanced_tracker.cpp | â³ | â­â­â­ |
| dynamic_removal/dynamic_filter.cpp | â³ | â­â­â­ |
| point_cloud_matching/advanced_matcher.cpp | â³ | â­â­â­ |
| factor_graph_opt/custom_factors.h | â³ | â­â­ |
| depth_estimation/depth_predictor.py | â³ | â­â­ |
| scripts/train_loop_detector.py | â³ | â­â­ |

---

## ğŸ” å®éªŒå·¥ä½œæµ

### å®Œæ•´çš„å®éªŒæµç¨‹

```
1. å‡†å¤‡æ•°æ®é›†
   â””â”€ ç¡®ä¿ home_data/husky.bag å’Œ gt.txt å­˜åœ¨

2. å»ºç«‹åŸºçº¿ (Week 1-2)
   â”œâ”€ è¿è¡ŒåŸå§‹LVI-SAM
   â”œâ”€ æå–è½¨è¿¹
   â””â”€ è¯„ä¼°æ€§èƒ½ â†’ experiments/baseline/

3. å•æ¨¡å—æ”¹è¿›æµ‹è¯• (Week 3-6)
   â”œâ”€ æ”¹è¿›1: è§†è§‰é‡Œç¨‹è®¡
   â”‚  â”œâ”€ å®ç°enhanced_tracker.cpp
   â”‚  â”œâ”€ é›†æˆåˆ°LVI-SAM
   â”‚  â””â”€ è¯„ä¼° â†’ experiments/improved_visual_v1/
   â”‚
   â”œâ”€ æ”¹è¿›2: æ¿€å…‰é‡Œç¨‹è®¡
   â”‚  â”œâ”€ å®ç°dynamic_filter.cpp
   â”‚  â”œâ”€ é›†æˆåˆ°mapOptmization
   â”‚  â””â”€ è¯„ä¼° â†’ experiments/improved_lidar_v1/
   â”‚
   â”œâ”€ æ”¹è¿›3: å›ç¯æ£€æµ‹
   â”‚  â”œâ”€ è®­ç»ƒæ·±åº¦æ¨¡å‹
   â”‚  â”œâ”€ é›†æˆåˆ°ç³»ç»Ÿ
   â”‚  â””â”€ è¯„ä¼° â†’ experiments/improved_loop_v1/
   â”‚
   â””â”€ æ”¹è¿›4: å› å­å›¾ä¼˜åŒ–
      â”œâ”€ æ·»åŠ æ–°çº¦æŸå› å­
      â”œâ”€ é›†æˆåˆ°GTSAM
      â””â”€ è¯„ä¼° â†’ experiments/improved_factor_v1/

4. ç»¼åˆæ”¹è¿›æµ‹è¯• (Week 7-8)
   â”œâ”€ æ•´åˆæ‰€æœ‰æ”¹è¿›
   â”œâ”€ è¶…å‚æ•°è°ƒä¼˜
   â””â”€ è¯„ä¼° â†’ experiments/final_evaluation/

5. æ€§èƒ½æŠ¥å‘Š (Week 8-9)
   â”œâ”€ ç”Ÿæˆå¯¹æ¯”è¡¨å’Œå›¾è¡¨
   â”œâ”€ æ’°å†™å®Œæ•´æŠ¥å‘Š
   â””â”€ æŠ¥å‘Š â†’ reports/final_report.md
```

---

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡

åŸºäºç›¸å…³ç ”ç©¶å’Œåˆæ­¥åˆ†æï¼š

| æ”¹è¿›é¡¹ | é¢„æœŸAPEæ”¹è¿› | é¢„æœŸATEæ”¹è¿› | é¢„æœŸAREæ”¹è¿› |
|--------|-----------|-----------|-----------|
| è§†è§‰å¢å¼º | +5-10% | +3-8% | +2-5% |
| æ¿€å…‰å¢å¼º | +10-15% | +8-12% | +5-8% |
| å›ç¯æ”¹è¿› | +5-8% | +5-10% | +3-6% |
| å› å­ä¼˜åŒ– | +3-5% | +5-8% | +2-4% |
| **å…¨éƒ¨ç»„åˆ** | **+20-35%** | **+25-40%** | **+12-20%** |

---

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿéœ€æ±‚
- Ubuntu 20.04 LTS
- ROS Noetic
- CUDA 11.0+ (å¯é€‰, ç”¨äºGPUåŠ é€Ÿ)
- 16GB+ å†…å­˜
- 100GB+ ç£ç›˜ç©ºé—´

### å…³é”®åº“ç‰ˆæœ¬
```
OpenCV >= 4.0
PCL >= 1.10
GTSAM >= 4.0
Ceres >= 1.14
PyTorch >= 1.9
Python >= 3.8
```

### å®‰è£…å‘½ä»¤
```bash
# ç³»ç»Ÿä¾èµ–
sudo apt-get update
sudo apt-get install -y \
    python3-dev \
    python3-pip \
    libeigen3-dev \
    libboost-all-dev \
    libomp-dev

# PythonåŒ…
pip install -r requirements.txt
```

---

## ğŸ“š ä¸»è¦å‚è€ƒæ–‡çŒ®

1. **LVI-SAM**
   - Shan, Z., Li, R., & Schwertfeger, S. (2021). "LVI-SAM: Tightly-Coupled Lidar-Visual-Inertial Odometry and Mapping"
   - GitHub: https://github.com/TixiaoShan/LVI-SAM

2. **VINS-Mono**
   - Qin, T., Li, P., & Shen, S. (2018). "VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator"

3. **LIO-SAM**
   - Shan, Z., Englot, B., Meyers, D., Wang, W., Ratti, C., & Rus, D. (2020). "LIO-SAM: Tightly-Coupled Lidar Inertial Odometry and Mapping"

4. **æ·±åº¦å­¦ä¹ ç‰¹å¾**
   - DeTone, D., Malisiewicz, T., & Rabinovich, A. (2018). "SuperPoint: Self-Supervised Interest Point Detection and Description"

5. **EVOå·¥å…·**
   - Grupp, M. (2017). "EVO: Python package for the evaluation of odometry and SLAM"

## ğŸŒ å…³é”®ä»£ç ä»“åº“ä¸å‚è€ƒ

### æ ¸å¿ƒæ¡†æ¶ä¸é¡¹ç›®

```markdown
## ä¸»è¦å‚è€ƒä»“åº“

### 1. LVI-SAM å®˜æ–¹æ¡†æ¶
- **ä»“åº“**: https://github.com/TixiaoShan/LVI-SAM
- **å‘è¡¨**: ICRA 2021
- **æ ¸å¿ƒ**: ç´§è€¦åˆLiDAR-è§†è§‰-æƒ¯æ€§SLAMç³»ç»Ÿ
- **è¯­è¨€**: C++
- **ä¾èµ–**: ROS, GTSAM, Ceres, OpenCV

### 2. LVI-SAM-Easyused (æœ¬é¡¹ç›®æ ¸å¿ƒå‚è€ƒ)
- **ä»“åº“**: https://github.com/NeSC-IV/LVI-SAM-Easyused
- **åˆ†æ”¯**: `new` åˆ†æ”¯ï¼ˆæ¨èä½¿ç”¨ï¼‰
- **æ”¹è¿›**: ä¿®å¤äº†å¤–å‚é…ç½®æ··ä¹±ï¼Œé›†æˆäº†æœ€æ–°LIO-SAMç‰ˆæœ¬
- **ä¼˜åŠ¿**:
  - ç®€åŒ–äº†ä¼ æ„Ÿå™¨å¤–å‚é…ç½®æµç¨‹
  - ä¿®å¤äº†åŸå§‹LVI-SAMä¸­å­˜åœ¨çš„Bug
  - æ”¯æŒå¤šç§æ•°æ®é›†é…ç½®
  - å®Œæ•´çš„å‚æ•°é…ç½®ç¤ºä¾‹

### 3. ç›¸å…³åŸºç¡€æ¡†æ¶
- **LIO-SAM**: https://github.com/TixiaoShan/LIO-SAM
  - LiDAR-æƒ¯æ€§é‡Œç¨‹è®¡ï¼Œæ˜¯LVI-SAMçš„æ¿€å…‰é‡Œç¨‹è®¡æ¨¡å—åŸºç¡€
- **ORB-SLAM2**: https://github.com/UZ-SLAM/ORB_SLAM2
  - è§†è§‰SLAMå‚è€ƒå®ç°
- **VINS-Mono**: https://github.com/HKUST-Aerial-Robotics/VINS-Mono
  - å•ç›®è§†è§‰-æƒ¯æ€§ç³»ç»Ÿå‚è€ƒ

---

## ğŸ’» ç¯å¢ƒé…ç½®å‚è€ƒ

æ ¹æ®LVI-SAM-Easyusedå®˜æ–¹æŒ‡å—ï¼Œæ¨èé…ç½®ï¼š

### æ“ä½œç³»ç»Ÿä¸åŸºç¡€åº“
```bash
# æ“ä½œç³»ç»Ÿ: Ubuntu 20.04
# ROSç‰ˆæœ¬: ROS Noetic
# å…¶ä»–åº“:
  - OpenCV 4.0.* 
  - GTSAM 4.0.*
  - Ceres 1.14.*
  - Eigen3
```

### ç¼–è¯‘æ­¥éª¤
```bash
# åˆ›å»ºå·¥ä½œç©ºé—´
mkdir -p ~/lvi-sam/src
cd ~/lvi-sam/src

# å…‹éš†ä»£ç ï¼ˆæ¨èä½¿ç”¨ new åˆ†æ”¯ï¼‰
git clone -b new https://github.com/NeSC-IV/LVI-SAM-Easyused.git
# æˆ–å…‹éš†å®˜æ–¹ç‰ˆæœ¬
git clone https://github.com/TixiaoShan/LVI-SAM.git

# ç¼–è¯‘
cd ~/lvi-sam
catkin_make
```

### æ ¸å¿ƒé…ç½®æ–‡ä»¶

#### 1. ä¼ æ„Ÿå™¨å¤–å‚é…ç½® (`params_camera.yaml`)
```yaml
# Camera-IMU å¤–å‚ (T_imu_camera)
# ç›¸æœºç›¸å¯¹äºIMUçš„æ—‹è½¬çŸ©é˜µ
extrinsicRotation: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [ 0,    0,    -1, 
           -1,     0,    0, 
            0,     1,    0]

# ç›¸æœºç›¸å¯¹äºIMUçš„ä½ç§»å‘é‡
extrinsicTranslation: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [0.006422381632411965, 0.019939800449065116, 0.03364235163589248]
```

#### 2. LiDARå¤–å‚é…ç½® (`params_lidar.yaml`)
```yaml
# LiDAR-IMU å¤–å‚ (T_imu_lidar)
extrinsicRotation: [-1,   0,    0, 
                     0,    1,    0, 
                     0,    0,   -1]
extrinsicTranslation: [0.0, 0.0, 0.0]
```

#### 3. IMUå±æ€§é…ç½®
```yaml
# IMUåæ ‡ç³»å®šä¹‰ï¼ˆç»•å“ªä¸ªè½´é€†æ—¶é’ˆæ—‹è½¬å¾—åˆ°æ­£æ¬§æ‹‰è§’ï¼‰
# å¯¹äºå¤§å¤šæ•°IMUè®¾ç½®ä¸ºï¼š"+z", "+y", "+x"
yawAxis: "+z"      # Yawè½´
pitchAxis: "+y"    # Pitchè½´  
rollAxis: "+x"     # Rollè½´
```

### è¿è¡Œç³»ç»Ÿ

```bash
# åŠ è½½ç¯å¢ƒå˜é‡
source ~/lvi-sam/devel/setup.bash

# å¯åŠ¨LVI-SAMç³»ç»Ÿï¼ˆä½¿ç”¨Huskyé…ç½®ï¼‰
roslaunch lvi_sam Husky.launch

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æ’­æ”¾æ•°æ®åŒ…
rosbag play your_data.bag
```

### è¯„ä¼°ä¸éªŒè¯

```bash
# 1. å®‰è£…EVOå·¥å…·
pip install evo --upgrade --no-binary evo

# 2. è½¬æ¢ç‚¹äº‘æ ¼å¼ï¼ˆå¦‚éœ€è¦ï¼‰
python pcd2tum.py

# 3. è®¡ç®—è½¨è¿¹è¯¯å·®
# -r full: åŒ…æ‹¬æ—‹è½¬å’Œå¹³ç§»
# -va: æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
evo_ape tum gt.txt lvisam.txt -r full -va --plot --plot_mode xy --save_plot

# 4. å¤šè½¨è¿¹å¯¹æ¯”
evo_traj tum trajectory1.txt trajectory2.txt --ref=gt.txt -va -p --plot_mode=xy --save_plot
```

### æ”¯æŒçš„æ•°æ®é›†é…ç½®

#### å®˜æ–¹LVI-SAMæ•°æ®é›†
```bash
roslaunch lvi_sam run.launch
rosbag play handheld.bag
```

#### M2DGR Dataset
```bash
roslaunch lvi_sam M2DGR.launch
rosbag play gate_01.bag
```

#### UrbanNav Dataset
```bash
roslaunch lvi_sam UrbanNavDataset.launch
rosbag play 2020-03-14-16-45-35.bag
```

#### KITTI Raw Dataset
```bash
roslaunch lvi_sam KITTI.launch
rosbag play kitti_2011_09_26_drive_0084_synced.bag
```

#### KAIST Complex Urban Dataset
```bash
roslaunch lvi_sam KAIST.launch
rosbag play urban26.bag
```

---

## ğŸ“š å…³é”®å‚è€ƒæ–‡çŒ®

### å­¦æœ¯è®ºæ–‡ä¸å®Œæ•´BibTeXæ ¼å¼

```bibtex
@inproceedings{shan2021lvi,
  title={LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry and Mapping},
  author={Shan, Tixiao and Englot, Brendan and Forster, Dariush and Meyers, Kyle and Wang, Devansh and Duarte, Carlos and Ratti, Carlo},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7482--7488},
  year={2021},
  organization={IEEE}
}

@inproceedings{shan2020liosam,
  title={LIO-SAM: Tightly-synchronized Lidar Inertial Odometry and Mapping},
  author={Shan, Tixiao and Englot, Brendan and Meyers, Kyle and Wang, Devansh and Ratti, Carlo and Rus, Daniela},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5016--5023},
  year={2020},
  organization={IEEE}
}
```

### ç‰¹å¾è·Ÿè¸ªç®—æ³•

```bibtex
@inproceedings{rublee2011orb,
  title={ORB: An Efficient Alternative to SIFT or SURF},
  author={Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
  booktitle={2011 International Conference on Computer Vision (ICCV)},
  pages={2564--2571},
  year={2011},
  organization={IEEE}
}

@article{lucas1981iterative,
  title={An Iterative Image Registration Technique with an Application to Stereo Vision},
  author={Lucas, Bruce D and Kanade, Takeo},
  journal={IJCAI},
  volume={81},
  pages={674--679},
  year={1981}
}

@inproceedings{desuperpoint,
  title={SuperPoint: Self-Supervised Interest Point Detection and Description},
  author={DeTone, Daniel and Malisiewicz, Tomasz and Rabinovich, Andrew},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages={224--236},
  year={2018},
  organization={IEEE}
}
```

### ç‚¹äº‘å¤„ç†ä¸é…å‡†

```bibtex
@article{besl1992method,
  title={Method for Registration of 3-D Shapes},
  author={Besl, Paul J and McKay, Neil D},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={14},
  number={2},
  pages={239--256},
  year={1992},
  publisher={IEEE}
}

@inproceedings{biber2003normal,
  title={The Normal Distributions Transform: A New Approach to Laser Scan Matching},
  author={Biber, Peter and StraÃŸer, Wolfgang},
  booktitle={Proceedings of the 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003)},
  volume={3},
  pages={2743--2748},
  year={2003},
  organization={IEEE}
}

@inproceedings{generalizedicp,
  title={Generalized-ICP},
  author={Segal, Aleksandr V and Haehnel, Dirk and Thrun, Sebastian},
  booktitle={Robotics: Science and Systems},
  volume={2},
  pages={435},
  year={2009}
}
```

### æ·±åº¦å­¦ä¹ æ–¹æ³•

```bibtex
@inproceedings{siamese2015,
  title={Siamese Neural Networks for One-shot Image Recognition},
  author={Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
  booktitle={ICML Deep Learning Workshop},
  year={2015}
}

@article{resnet2015,
  title={Deep Residual Learning for Image Recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal={arXiv preprint arXiv:1512.03385},
  year={2015}
}

@inproceedings{he2016deep,
  title={Deep Learning for Generic Object Detection: A Survey},
  author={He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},
  pages={2395--2403},
  year={2015},
  organization={IEEE}
}

@inproceedings{mobilenet2017,
  title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  author={Howard, Andrew G and Zhu, Mengxi and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijing and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={4234--4243},
  year={2017},
  organization={IEEE}
}
```

### è§†è§‰SLAMåŸºç¡€

```bibtex
@article{orbslam2,
  title={ORB-SLAM2: An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras},
  author={Mur-Artal, Ra{\'u}l and Tard{\'o}s, Juan D},
  journal={IEEE Transactions on Robotics},
  volume={33},
  number={5},
  pages={1255--1262},
  year={2017},
  publisher={IEEE}
}

@inproceedings{vinsmonorig,
  title={VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator},
  author={Qin, Tong and Li, Peiliang and Shen, Shaojun},
  booktitle={IEEE Transactions on Robotics},
  volume={34},
  number={4},
  pages={1004--1020},
  year={2018},
  publisher={IEEE}
}

@inproceedings{dso2018,
  title={Direct Sparse Odometry},
  author={Wang, Rui and SchwÃ¶rer, Martin and Cremers, Daniel},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  pages={373--382},
  year={2017},
  organization={IEEE}
}
```

### è¯„ä¼°ä¸åŸºå‡†

```bibtex
@techreport{geiger2012kitti,
  title={Vision meets Robotics: The KITTI Dataset},
  author={Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  journal={International Journal of Robotics Research},
  year={2013}
}

@article{evo2017,
  title={EVO: Accurate and Open Source ROS Trajectory Evaluation Tool},
  author={Grupp, Michael},
  year={2017},
  url={https://github.com/MichaelGrupp/evo}
}

@inproceedings{ate2009,
  title={Accurate Real-time Localization of an Articulated Surgical Instrument using Kinematic and Optical Markers},
  author={Lepetit, Vincent and Fua, Pascal},
  booktitle={International Symposium on Computer Vision},
  year={2006}
}
```

---


### å¸¸è§é—®é¢˜

**Q: è¿è¡Œæ—¶å‡ºç°å†…å­˜ä¸è¶³ï¼Ÿ**
A: ä½¿ç”¨ä½“ç´ æ»¤æ³¢å™¨é™é‡‡æ ·ç‚¹äº‘ï¼Œæˆ–åœ¨`launch`æ–‡ä»¶ä¸­å‡å°‘`max_features`å‚æ•°

**Q: GPUå†…å­˜æº¢å‡ºï¼ˆdeep learningæ¨¡å—ï¼‰ï¼Ÿ**
A: å‡å°‘batch_sizeæˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆMobileNetæ›¿ä»£ResNetï¼‰

**Q: è½¨è¿¹è¯„ä¼°å‡ºé”™ï¼Ÿ**
A: ç¡®ä¿è½¨è¿¹æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆTUMæ ¼å¼ï¼‰ï¼Œæ—¶é—´æˆ³å•è°ƒé€’å¢

**Q: ç½‘ç»œè®­ç»ƒå¾ˆæ…¢ï¼Ÿ**
A: å¯ç”¨GPUåŠ é€Ÿï¼Œæ£€æŸ¥CUDAå¯ç”¨æ€§ï¼š`python -c "import torch; print(torch.cuda.is_available())"`


